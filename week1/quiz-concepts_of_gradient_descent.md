# Quiz - Concepts of Gradient Descent
**Q: Why is it important to scal e features for Gradient Descent?**

A: It precents getting stuck in local optima and speeds up

**Q: For a single variable linear regression problem, how many parameters need to be estimated?**

A: 2

**Q: If training data has 100 samples, how many samples should ideally be used for each step in a "Batch" gradient descent?**

A: All the samples

**Q: If a data set has 10 samples and 50 features per sample, then the following should be considered to ensure regression model convergence:**

A: Feature reduction, Regularization, Pseudo inverse (may be useful)
