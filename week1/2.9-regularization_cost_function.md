# 2.9 Regularization Cost Function

Regularization forces us to maintain small values for our parameter vector, Î¸.
    * Results in a "simpler" hypothesis
    * Less prone to overfitting

We add a regularization parameter to our cost function. Where Lambda is the regularization parameter. Lamdbda controls the tradeoff between two goals:

    1. Goal of fitting the training set
    2. keeping the parameters small

It can be difficult to intuit why reducing the parameter size will reduce overfitting.

If Lambda were set to an extremely large value, then we would significantly underfit our data. Care should be taken to choose the regularization parameter, theta.
