# Multivariate Linear Regression
Imagine we had more than one variable available to help us predict the price of a house. Say we have the size, # of bedrooms, # of floors, and age. So now we have an x1, x2, x3 and x4, but still one y, price.

---
Let's define some important notation:

m = number of training examples (rows of data)

n =  of features (4 in this case x1 -> x4)

x<sup>i</sup> = input (features) of the i<sup>th</sup> training example

x<sup>i</sup><sub>j</sub> = value of feature j in the i<sup>th</sup> training example

## Sample Data
| Size (x<sub>1</sub>)      | # of Bedrooms (x<sub>2</sub>) | # of floors (x<sub>3</sub>)| Age (x<sub>4</sub>) | Price (y) |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2104      | 5       | 1     | 45       | 460      |
| 1416   | 3        | 2   | 40        | 232   |
| 1534   | 3        | 2   | 30        | 315   |
| 852   | 2        | 1   | 36        | 178   |
| ...   | ...        | ...   | ...        | ...   |

With this example, the definitions can be seen more clearly: 

x<sup>2</sup> = [1416, 3, 2, 40]

x<sup>2</sup><sub>3</sub> = 2

## Reforming our hypothesis
Previously: h<sub>θ</sub>(x) = θ<sub>0</sub> + θ<sub>1</sub>x

Now:  h<sub>θ</sub>(x) = θ<sub>0</sub> + θ<sub>1</sub>x<sub>1</sub> + θ<sub>2</sub>x<sub>2</sub> + θ<sub>3</sub>x<sub>3</sub> + θ<sub>4</sub>x<sub>4</sub> + ... + θ<sub>n</sub>x<sub>n</sub>

For convenience, we introduce a parameter, x<sub>0</sub> = 1.

This changes the first parameter in our above equation to  θ<sub>0</sub> = θ<sub>0</sub>x<sub>0</sub>

## Simplifying into Vector Multiplication
We can now simplify these into two vectors, θ and x:

h<sub>θ</sub>(x) = θ<sup>T</sup>x
